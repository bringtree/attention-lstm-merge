{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9477780000000001\n",
      "INFO:tensorflow:Restoring parameters from ./test_model/0/acc_0.93947_lstm_hid_100_full_hid_0_att_hid_0_dropout_0.3_0.2_0.3/-46\n",
      "INFO:tensorflow:Restoring parameters from ./test_model/1/acc_0.94474_lstm_hid_300_full_hid_0_att_hid_0_dropout_0.2_0.3_0.3/-30\n",
      "INFO:tensorflow:Restoring parameters from ./test_model/2/acc_0.94974_lstm_hid_100_full_hid_0_att_hid_0_dropout_0.3_0.3_0.3/-46\n",
      "INFO:tensorflow:Restoring parameters from ./test_model/3/acc_0.96552_lstm_hid_300_full_hid_0_att_hid_0_dropout_0.3_0.2_0.3/-42\n",
      "INFO:tensorflow:Restoring parameters from ./test_model/4/acc_0.944_lstm_hid_100_full_hid_0_att_hid_0_dropout_0.3_0.2_0.3/-40\n",
      "INFO:tensorflow:Restoring parameters from ./test_model/5/acc_0.93298_lstm_hid_150_full_hid_0_att_hid_0_dropout_0.3_0.2_0.3/-27\n",
      "INFO:tensorflow:Restoring parameters from ./test_model/6/acc_0.95699_lstm_hid_100_full_hid_0_att_hid_0_dropout_0.2_0.3_0.3/-59\n",
      "INFO:tensorflow:Restoring parameters from ./test_model/7/acc_0.97027_lstm_hid_150_full_hid_0_att_hid_0_dropout_0.3_0.2_0.3/-47\n",
      "INFO:tensorflow:Restoring parameters from ./test_model/8/acc_0.9455_lstm_hid_50_full_hid_0_att_hid_0_dropout_0.3_0.3_0.3/-80\n",
      "INFO:tensorflow:Restoring parameters from ./test_model/9/acc_0.92857_lstm_hid_300_full_hid_0_att_hid_0_dropout_0.3_0.3_0.3/-60\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from monitor import Monitor\n",
    "import joblib\n",
    "from data_model import DataModel\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "model_src_list = []\n",
    "model_args_list = []\n",
    "father_model_name = './test_model/'\n",
    "sum = 0\n",
    "for i in range(10):\n",
    "    model_list = [model_name.split('_') for model_name in os.listdir(father_model_name + str(i))]\n",
    "    model_list = sorted(model_list, key=lambda s: s[1], reverse=True)\n",
    "    model_name = model_list[0]\n",
    "    model_args_list.append({\n",
    "        'hidden': model_name[4],\n",
    "        'full_hidden_num':model_name[7],\n",
    "        'attention': model_name[10]\n",
    "    })\n",
    "    \n",
    "    sum += float(model_name[1])\n",
    "    model_name = \"_\".join(model_name)\n",
    "    model_src_list.append(father_model_name + str(i) + '/' + model_name + '/')\n",
    "\n",
    "print(sum / 10)\n",
    "\n",
    "output_list = []\n",
    "predict_intent_list = []\n",
    "attention_rate_list = []\n",
    "\n",
    "word2idx = joblib.load('./preprocessing_data/word2idx.pkl')\n",
    "label2idx = joblib.load('./preprocessing_data/label2idx.pkl')\n",
    "idx2vec = joblib.load('./preprocessing_data/idx2vec.pkl')\n",
    "idx2label = joblib.load('./preprocessing_data/idx2label.pkl')\n",
    "\n",
    "raw_data = [[], [], *DataModel(1).test_data]\n",
    "\n",
    "for k_idx in range(10):\n",
    "    model_src = model_src_list[k_idx]\n",
    "    model_args = model_args_list[k_idx]\n",
    "    sub_model = Monitor(data=raw_data, word2idx_dict=word2idx, label2idx_dict=label2idx,\n",
    "                        idx2vec_dict=idx2vec, idx2label_dict=idx2label,\n",
    "                        sentence_fixed_len=50, learning_rate=0.001, word_vec_size=400,\n",
    "                        hidden_num=int(model_args['hidden']),full_hidden_num=int(model_args['full_hidden_num']), attention_num=int(model_args['attention']),\n",
    "                        label_num=31, k_model_src=model_src)\n",
    "    sub_model.load_model(model_src=model_src)\n",
    "    output_list.append(sub_model.get_attention_information('', train_data_mode=False))\n",
    "\n",
    "intent = output_list[0][1]\n",
    "sentence = output_list[0][0]\n",
    "sentence_length = output_list[0][2]\n",
    "predict_intent = []\n",
    "attention_rate = []\n",
    "\n",
    "pre_int = []                        ############\n",
    "pre_int_time = []                   ############\n",
    "pre_att = []                        ############\n",
    "\n",
    "for sentence_idx in range(len(sentence)):\n",
    "    intent_time = []\n",
    "    tmp_attention_rate = np.zeros(50)\n",
    "\n",
    "    tmp_intent_time = -1            ############\n",
    "    pre_int.append({})              ############\n",
    "    pre_int_time.append({})         ############\n",
    "    pre_att.append([])              ############\n",
    "\n",
    "    for model_idx in range(len(output_list)):\n",
    "        intent_time.append(output_list[model_idx][4][sentence_idx])\n",
    "        tmp_attention_rate += output_list[model_idx][3][sentence_idx]\n",
    "\n",
    "        if intent_time[-1] not in pre_int[-1]:                                      ############\n",
    "            pre_int[-1][intent_time[-1]] = tmp_intent_time = tmp_intent_time + 1    ############\n",
    "            pre_int_time[-1][intent_time[-1]] = 0                                   ############\n",
    "            pre_att[-1].append(np.zeros(50))\n",
    "\n",
    "        pre_int_time[-1][intent_time[-1]] += 1                                                  ############\n",
    "        pre_att[-1][pre_int[-1][intent_time[-1]]] += output_list[model_idx][3][sentence_idx]    ############\n",
    "\n",
    "    predict_intent.append(Counter(intent_time).most_common(1)[0][0])\n",
    "    attention_rate.append([str(v) for v in list(tmp_attention_rate / len(output_list))])        ############\n",
    "    for i_intent in pre_int[-1].keys():                                                         ############\n",
    "        pre_att[-1][pre_int[-1][i_intent]] /= pre_int_time[-1][i_intent]                        ############\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3558\n",
      "0.7857773851590106\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "mistake = 0\n",
    "with open('att_test_all_case.csv', 'w') as fp:\n",
    "    for i in range(len(sentence)):\n",
    "        if intent[i] == idx2label[predict_intent[i]]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            mistake += 1\n",
    "        \n",
    "        for i_intent in pre_int[i].keys():    \n",
    "            fp.writelines((intent[i] + ',' + ','.join(sentence[i][:sentence_length[i]]) + ',\\n'))\n",
    "            fp.writelines((idx2label[i_intent]+ '(' + str(pre_int_time[i][i_intent]) + ')' + ',' +  \n",
    "                           ','.join([str(j) \n",
    "                            for j in list(pre_att[i][pre_int[i][i_intent]][:sentence_length[i]])]) + \n",
    "                           \",\\n\"))   \n",
    "\n",
    "print(correct)\n",
    "print(correct / (mistake + correct))\n",
    "\n",
    "with open('att_test_badcase.csv', 'w') as fp:\n",
    "    for i in range(len(sentence)):\n",
    "        if intent[i] == idx2label[predict_intent[i]]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            mistake += 1\n",
    "            \n",
    "            for i_intent in pre_int[i].keys():                 \n",
    "                fp.writelines((intent[i] + ',' + ','.join(sentence[i][:sentence_length[i]]) + ',\\n'))\n",
    "                fp.writelines((idx2label[i_intent]+ '(' + str(pre_int_time[i][i_intent]) + ')' + ',' +\n",
    "                               ','.join([str(j)\n",
    "                                for j in list(pre_att[i][pre_int[i][i_intent]][:sentence_length[i]])]) + \n",
    "                                \",\\n\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9405660000000001\n",
      "[['0.3', '0.3', '0.3', 'dropout', '0', 'hid', 'att', '0', 'hid', 'full', '300', 'hid', 'lstm', '0.92761', 'acc', '5'], ['0.3', '0.3', '0.3', 'dropout', '0', 'hid', 'att', '0', 'hid', 'full', '300', 'hid', 'lstm', '0.92857', 'acc', '9'], ['0.3', '0.3', '0.3', 'dropout', '0', 'hid', 'att', '0', 'hid', 'full', '300', 'hid', 'lstm', '0.93421', 'acc', '0'], ['0.3', '0.3', '0.3', 'dropout', '0', 'hid', 'att', '0', 'hid', 'full', '300', 'hid', 'lstm', '0.93651', 'acc', '2'], ['0.3', '0.3', '0.3', 'dropout', '0', 'hid', 'att', '0', 'hid', 'full', '300', 'hid', 'lstm', '0.93733', 'acc', '8'], ['0.3', '0.3', '0.3', 'dropout', '0', 'hid', 'att', '0', 'hid', 'full', '300', 'hid', 'lstm', '0.93867', 'acc', '4'], ['0.3', '0.3', '0.3', 'dropout', '0', 'hid', 'att', '0', 'hid', 'full', '300', 'hid', 'lstm', '0.93947', 'acc', '1'], ['0.3', '0.3', '0.3', 'dropout', '0', 'hid', 'att', '0', 'hid', 'full', '300', 'hid', 'lstm', '0.94892', 'acc', '6'], ['0.3', '0.3', '0.3', 'dropout', '0', 'hid', 'att', '0', 'hid', 'full', '300', 'hid', 'lstm', '0.95491', 'acc', '3'], ['0.3', '0.3', '0.3', 'dropout', '0', 'hid', 'att', '0', 'hid', 'full', '300', 'hid', 'lstm', '0.95946', 'acc', '7']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.602 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./test_model/5/acc_0.92761_lstm_hid_300_full_hid_0_att_hid_0_dropout_0.3_0.3_0.3/-8\n",
      "INFO:tensorflow:Restoring parameters from ./test_model/9/acc_0.92857_lstm_hid_300_full_hid_0_att_hid_0_dropout_0.3_0.3_0.3/-60\n",
      "INFO:tensorflow:Restoring parameters from ./test_model/0/acc_0.93421_lstm_hid_300_full_hid_0_att_hid_0_dropout_0.3_0.3_0.3/-25\n",
      "INFO:tensorflow:Restoring parameters from ./test_model/2/acc_0.93651_lstm_hid_300_full_hid_0_att_hid_0_dropout_0.3_0.3_0.3/-40\n",
      "INFO:tensorflow:Restoring parameters from ./test_model/8/acc_0.93733_lstm_hid_300_full_hid_0_att_hid_0_dropout_0.3_0.3_0.3/-22\n",
      "INFO:tensorflow:Restoring parameters from ./test_model/4/acc_0.93867_lstm_hid_300_full_hid_0_att_hid_0_dropout_0.3_0.3_0.3/-23\n",
      "INFO:tensorflow:Restoring parameters from ./test_model/1/acc_0.93947_lstm_hid_300_full_hid_0_att_hid_0_dropout_0.3_0.3_0.3/-45\n",
      "INFO:tensorflow:Restoring parameters from ./test_model/6/acc_0.94892_lstm_hid_300_full_hid_0_att_hid_0_dropout_0.3_0.3_0.3/-33\n",
      "INFO:tensorflow:Restoring parameters from ./test_model/3/acc_0.95491_lstm_hid_300_full_hid_0_att_hid_0_dropout_0.3_0.3_0.3/-33\n",
      "INFO:tensorflow:Restoring parameters from ./test_model/7/acc_0.95946_lstm_hid_300_full_hid_0_att_hid_0_dropout_0.3_0.3_0.3/-19\n",
      "3461\n",
      "0.7643551236749117\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from monitor import Monitor\n",
    "import joblib\n",
    "from data_model import DataModel\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "model_src_list = []\n",
    "model_args_list = []\n",
    "father_model_name = './test_model/'\n",
    "model_list = []\n",
    "sum = 0\n",
    "for i in range(10):\n",
    "    model_list += [[str(i)]+model_name.split('_') for model_name in os.listdir(father_model_name + str(i))]\n",
    "for i in model_list:\n",
    "    i.reverse()\n",
    "model_list.sort()\n",
    "i = 0\n",
    "sum = 0\n",
    "while (i + 10 <= len(model_list)):\n",
    "    if (model_list[i][0:-3] == model_list[i + 9][0:-3]):\n",
    "        tmp = 0\n",
    "        for j in range(i, i + 10):\n",
    "            tmp += float(model_list[j][-3])\n",
    "        tmp /= 10\n",
    "        if tmp > sum:\n",
    "            sum = tmp;\n",
    "            model_src_list = [model_list[j] for j in range(i,i + 10)]\n",
    "        i += 10\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "print(sum)\n",
    "print(model_src_list)\n",
    "\n",
    "for i in range(len(model_src_list)):\n",
    "    model_src_list[i].reverse()\n",
    "    #print(model_src_list[i])\n",
    "    model_args_list += [{'hidden': model_src_list[i][5],\n",
    "                         'full_hidden_num' : model_src_list[i][8],\n",
    "                         'attention' : model_src_list[i][11]}]\n",
    "    model_src_list[i] = father_model_name + str(model_src_list[i][0]) + '/' + \"_\".join(model_src_list[i][1:])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "output_list = []\n",
    "predict_intent_list = []\n",
    "attention_rate_list = []\n",
    "\n",
    "word2idx = joblib.load('./preprocessing_data/word2idx.pkl')\n",
    "label2idx = joblib.load('./preprocessing_data/label2idx.pkl')\n",
    "idx2vec = joblib.load('./preprocessing_data/idx2vec.pkl')\n",
    "idx2label = joblib.load('./preprocessing_data/idx2label.pkl')\n",
    "\n",
    "# def load():\n",
    "#     with open('./test_hyh.txt', encoding='utf8') as fp:\n",
    "#         tmp = [v.strip() for v in fp.readlines()]\n",
    "#     d = {}\n",
    "#     for i, j in enumerate(tmp):\n",
    "#         d[j] = i\n",
    "#     return d\n",
    "\n",
    "# d = load()\n",
    "raw_data = [[], [], *DataModel(1).test_data]\n",
    "#raw_data = [[], [], *DataModel(1).train_data]\n",
    "for k_idx in range(10):\n",
    "    model_src = model_src_list[k_idx]\n",
    "    model_args = model_args_list[k_idx]\n",
    "    sub_model = Monitor(data=raw_data, word2idx_dict=word2idx, label2idx_dict=label2idx,\n",
    "                        idx2vec_dict=idx2vec, idx2label_dict=idx2label,\n",
    "                        sentence_fixed_len=50, learning_rate=0.001, word_vec_size=400,\n",
    "                        hidden_num=int(model_args['hidden']),full_hidden_num=int(model_args['full_hidden_num']), attention_num=int(model_args['attention']),\n",
    "                        label_num=31, k_model_src=model_src)\n",
    "    sub_model.load_model(model_src=model_src)\n",
    "    output_list.append(sub_model.get_attention_information('', train_data_mode=False))\n",
    "\n",
    "intent = output_list[0][1]\n",
    "sentence = output_list[0][0]\n",
    "sentence_length = output_list[0][2]\n",
    "predict_intent = []\n",
    "attention_rate = []\n",
    "\n",
    "pre_int = []                        ############\n",
    "pre_int_time = []                   ############\n",
    "pre_att = []                        ############\n",
    "\n",
    "for sentence_idx in range(len(sentence)):\n",
    "    intent_time = []\n",
    "    tmp_attention_rate = np.zeros(50)\n",
    "\n",
    "    tmp_intent_time = -1            ############\n",
    "    pre_int.append({})              ############\n",
    "    pre_int_time.append({})         ############\n",
    "    pre_att.append([])              ############\n",
    "\n",
    "    for model_idx in range(len(output_list)):\n",
    "        intent_time.append(output_list[model_idx][4][sentence_idx])\n",
    "        tmp_attention_rate += output_list[model_idx][3][sentence_idx]\n",
    "\n",
    "        if intent_time[-1] not in pre_int[-1]:                                      ############\n",
    "            pre_int[-1][intent_time[-1]] = tmp_intent_time = tmp_intent_time + 1    ############\n",
    "            pre_int_time[-1][intent_time[-1]] = 0                                   ############\n",
    "            pre_att[-1].append(np.zeros(50))\n",
    "\n",
    "        pre_int_time[-1][intent_time[-1]] += 1                                                  ############\n",
    "        pre_att[-1][pre_int[-1][intent_time[-1]]] += output_list[model_idx][3][sentence_idx]    ############\n",
    "\n",
    "    predict_intent.append(Counter(intent_time).most_common(1)[0][0])\n",
    "    attention_rate.append([str(v) for v in list(tmp_attention_rate / len(output_list))])        ############\n",
    "    for i_intent in pre_int[-1].keys():                                                         ############\n",
    "        pre_att[-1][pre_int[-1][i_intent]] /= pre_int_time[-1][i_intent]                        ############\n",
    "\n",
    "        \n",
    "\n",
    "correct = 0\n",
    "mistake = 0\n",
    "ans = []\n",
    "\n",
    "with open('att_test_all_case.csv', 'w') as fp:\n",
    "    for i in range(len(sentence)):\n",
    "        if intent[i] == idx2label[predict_intent[i]]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            mistake += 1\n",
    "        \n",
    "        mx = 0\n",
    "        output = \"\"\n",
    "        for i_intent in pre_int[i].keys():\n",
    "            if pre_int_time[i][i_intent] > mx:\n",
    "                mx = pre_int_time[i][i_intent]\n",
    "                output = (idx2label[i_intent]+ '(' + str(pre_int_time[i][i_intent]) + ')' + ',' +\n",
    "                           ','.join([str(j)\n",
    "                            for j in list(pre_att[i][pre_int[i][i_intent]][:sentence_length[i]])]) + \n",
    "                            \",\\n\")\n",
    "#         ans = [ d[''.join(sentence[i][:sentence_length[i]])], \n",
    "#                (intent[i] + ',' + ','.join(sentence[i][:sentence_length[i]]) + ',\\n'), \n",
    "#                output ]\n",
    "        fp.writelines((intent[i] + ',' + ','.join(sentence[i][:sentence_length[i]]) + ',\\n'))\n",
    "        fp.writelines(output)\n",
    "#     ans.sort()\n",
    "#     for i in ans:\n",
    "#         fp.writelines(ans[1])\n",
    "#         fp.writelines(ans[2])\n",
    "        \n",
    "#         for i_intent in pre_int[i].keys():    \n",
    "#            fp.writelines((intent[i] + ',' + ','.join(sentence[i][:sentence_length[i]]) + ',\\n'))\n",
    "#            fp.writelines((idx2label[i_intent]+ '(' + str(pre_int_time[i][i_intent]) + ')' + ',' +  \n",
    "#                           ','.join([str(j) \n",
    "#                            for j in list(pre_att[i][pre_int[i][i_intent]][:sentence_length[i]])]) + \n",
    "#                           \",\\n\"))   \n",
    "    \n",
    "print(correct)\n",
    "print(correct / (mistake + correct))\n",
    "\n",
    "with open('att_test_badcase.csv', 'w') as fp:\n",
    "    for i in range(len(sentence)):\n",
    "        if intent[i] == idx2label[predict_intent[i]]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            mistake += 1\n",
    "            fp.writelines((intent[i] + ',' + ','.join(sentence[i][:sentence_length[i]]) + ',\\n'))\n",
    "            mx = 0\n",
    "            output = \"\"\n",
    "            for i_intent in pre_int[i].keys():\n",
    "                if pre_int_time[i][i_intent] > mx:\n",
    "                    mx = pre_int_time[i][i_intent]\n",
    "                    output = (idx2label[i_intent]+ '(' + str(pre_int_time[i][i_intent]) + ')' + ',' +\n",
    "                               ','.join([str(j)\n",
    "                                for j in list(pre_att[i][pre_int[i][i_intent]][:sentence_length[i]])]) + \n",
    "                                \",\\n\")\n",
    "            fp.writelines(output)\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
